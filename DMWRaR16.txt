Data Mining with Rattle and R: The Art of Excavating Data for Knowledge Discovery by Graham Williams

Chapter 16 DeploymentOnce a model is developed and evaluated, and we have determined it to be suitable, we then need to deploy it. This is an often-overlooked issue in many data mining projects. It also seems to receive little attention when setting up a data mining capability within an organization. Yet it is an important issue, as we need to ensure we obtain the benefit from the model.
In this chapter, we briefly consider a number of deployment options. We begin with considering a deployment in R. We also consider the conversion of our models into the Predictive Modeling Markup Language (PMML). This allows us to export our model to other systems, which includes systems that can convert the model into C code that can run as a stand-alone module.16.1 Deploying an R Model
A simple approach to deployment is to use predict() to apply the model to a new dataset. We often refer to this as “scoring.” Rattle’s evaluation tab supports scoring with the Score option of the Evaluate tab. There are a number of options available. The first is whether to score the training dataset, the validation dataset, the testing dataset, or some dataset loaded from a CSV file (which must contain the exact same variables). Any number of models can be selected, and the results (either as predicted values or probabilities) are written to a CSV file.Often, we will want to score a new dataset regularly as new observations become available. In this case, we will save the model for later use. The Rattle concept of a project, as discussed in Section 2.8, is useful in such a circumstance. This will save the current state of Rattle (including the actual data and models built during a session). At a later time, this project can be loaded into a new instance of Rattle (running on the same host or even a different host and operating system). A new dataset can then be scored using the saved model. To do so, we do not need to start up the Rattle GUI but simply access the relevant model (e.g., crs$rf) and apply it to some new data using predict().
As we see in Rattle’s Log tab, below the surface, when we save and load projects, we are simply using save() and load(). These create a binary representation of the R objects, saving them to a file and then loading them into R.
A Rattle project can get quite large, particularly with large datasets. Larger files take longer to load, and for deploying a model it is often not necessary to keep the original data. So as we get serious about deployment, we might save just the model we wish to deploy. This is done using save() to save the actual model.
After building a random forest model in Rattle using the weather dataset, we might save the model to a file by using save() in the R Console:

> myrf <- crs$rf> save(myrf, file="model01_110501.RData")
A warning message may be shown just to suggest that when reloading the binary file into a new instance of R, rattle might not have been loaded, and it is perhaps a good idea to do so. This is to ensure the objects that are saved are correctly interpreted by R.
We now want to simulate the application of the model to a new dataset. To do so, we might simply save the current dataset to a CSV file using write.csv():

> write.csv(crs$dataset, file="cases_110601.csv")
We can then load the model into a different instance of R at a later time using load() and apply (i.e., use predict() on) the model (using a script based on the commands shown in Rattle’s Log tab) to a new dataset. In this case, we then also write the results to another CSV file using write.csv():
> library(randomForest)> (load("model01_110501.RData"))[1] "myrf"> dataset <- read.csv("cases_110601.csv")> pr <- predict(myrf, dataset, type="prob")[,2]> write.csv(cbind(dataset, pr),            file="scores_110601.csv",            row.names=FALSE)> head(cbind(Actual=dataset$TARGET_Adjusted, Predicted=pr))Predicted1 0.6882 0.7123 0.9164 0.1645 0.0526 0.016
We can see that the random forest model is doing okay on these few observations.In practice, once model deployment has been approved, the model is deployed into a secure environment. We can then schedule the model to be applied regularly to a new dataset using a script that is very similar to that above. The dataset can be obtained from a data warehouse, for example, and the results populated back into the data warehouse. Other processes might then come into play to make use of the scores, perhaps to identify clients who need to be audited or to communicate to the weather forecaster the predicted likelihood of rain tomorrow.16.2 Converting to PMMLAn alternative approach to direct deployment within R is to export the model in some form so that it might be imported into other software for predictions on new data. Exporting a model to an open standard format facilitates this process. A model represented using this open standard representation can then be exported to a variety of other software or languages.The Predictive Model Markup Language (Guazzelli et al., 2010, 2009) (PMML) provides such a standard language for representing data mining models. PMML is an XML-based standard that is supported, to some extent, by the major commercial data mining vendors and many open source data mining tools.
The pmml package for R is responsible for exporting models from R to PMML. PMML models generated by Rattle using pmml() can be imported into a number of other products. The Export button (while displaying a model within the Model tab) will export a model as PMML.
We illustrate here the form that the PMML export takes. First, we again create a dataset object:> library(rattle)> weatherDS <- new.env()> evalq({data <- weathernobs <- nrow(data)vars <- -grep('^(Date|Locat|RISK)', names(weather)) set.seed(42)train <- sample(nobs, 0.7*nobs)form <- formula(RainTomorrow ~ .)  }, weatherDS)Next, we build the decision tree model:> library(rpart)> weatherRPART <- new.env(parent=weatherDS)> evalq({    model <- rpart(formula=form, data=data[train, vars])  }, weatherRPART)Now we can generate the PMML representation using pmml(). We then print some rows from the PMML representation of the model:> library(pmml)> p <- pmml(weatherRPART$model)> r <- c(1:4, 7, 12, 35, 36, 69, 71, 137:139)> cat(paste(strsplit(toString(p), "\n")[[1]][r],            collapse="\n"))<PMML version="3.2" xmlns="http://www.dmg.org/PMML-3_2"    xmlns=...> <Header copyright="Copyright (c) 2011 gjw"     description="RPart Decision Tree Model">  <Extension name="user" value="gjw" extender="Rattle"/>  <Application name="Rattle/PMML" version="1.2.27"/> <DataDictionary numberOfFields="21">  <DataField name="MinTemp" optype="continuous" .../> </DataDictionary> <TreeModel modelName="RPart_Model" ...>   <Node id="2" score="No" recordCount="204" ...>     <SimplePredicate field="Pressure3pm"     operator="greaterOrEqual" value="1011.9"/>  </Node> </TreeModel></PMML>
16.3 Command SummaryThis chapter has referenced the following R packages, commands, functions, and datasets:
load() command Load R objects from a file.
pmml() function Convert a model to PMML. 
pmml package Supports conversion of many models. 
predict() function Score a dataset using a model.
save() command Save R objects to a binary file.
